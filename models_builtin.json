{
  "version": "2.0",
  "description": "Built-in fallback model database. Edit this to add custom models. Run --update to fetch latest from HuggingFace.",
  "models": [
    {
      "name": "TinyLlama 1.1B",
      "provider": "TinyLlama",
      "family": "TinyLlama",
      "params": 1.1,
      "context": 2048,
      "ram": 4,
      "vram": 2,
      "quants": ["Q4_K_M", "Q5_K_M", "Q8_0"],
      "use_case": "chatbot",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "Phi-2 2.7B",
      "provider": "Microsoft",
      "family": "Phi",
      "params": 2.7,
      "context": 2048,
      "ram": 6,
      "vram": 3,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "coding",
      "tags": ["code", "reasoning"],
      "is_moe": false
    },
    {
      "name": "Phi-3 Mini 3.8B",
      "provider": "Microsoft",
      "family": "Phi",
      "params": 3.8,
      "context": 128000,
      "ram": 8,
      "vram": 4,
      "quants": ["Q4_K_M", "Q5_K_M", "Q8_0"],
      "use_case": "coding",
      "tags": ["code", "chat"],
      "is_moe": false
    },
    {
      "name": "Gemma 2B",
      "provider": "Google",
      "family": "Gemma",
      "params": 2,
      "context": 8192,
      "ram": 5,
      "vram": 3,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "Qwen2 1.5B",
      "provider": "Alibaba",
      "family": "Qwen",
      "params": 1.5,
      "context": 32768,
      "ram": 4,
      "vram": 2,
      "quants": ["Q4_K_M", "Q5_K_M", "Q8_0"],
      "use_case": "general",
      "tags": ["chat", "multilingual"],
      "is_moe": false
    },
    {
      "name": "Mistral 7B v0.3",
      "provider": "Mistral AI",
      "family": "Mistral",
      "params": 7,
      "context": 32768,
      "ram": 16,
      "vram": 6,
      "quants": ["Q3_K_M", "Q4_K_M", "Q5_K_M", "Q8_0"],
      "use_case": "general",
      "tags": ["chat", "coding"],
      "is_moe": false
    },
    {
      "name": "LLaMA 3 8B",
      "provider": "Meta",
      "family": "LLaMA",
      "params": 8,
      "context": 8192,
      "ram": 16,
      "vram": 6,
      "quants": ["Q4_K_M", "Q5_K_M", "Q8_0"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "LLaMA 3.1 8B",
      "provider": "Meta",
      "family": "LLaMA",
      "params": 8,
      "context": 128000,
      "ram": 16,
      "vram": 6,
      "quants": ["Q4_K_M", "Q5_K_M", "Q8_0"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "CodeLlama 7B",
      "provider": "Meta",
      "family": "CodeLlama",
      "params": 7,
      "context": 16384,
      "ram": 16,
      "vram": 6,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "coding",
      "tags": ["code"],
      "is_moe": false
    },
    {
      "name": "Gemma 7B",
      "provider": "Google",
      "family": "Gemma",
      "params": 7,
      "context": 8192,
      "ram": 16,
      "vram": 6,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "Gemma 2 9B",
      "provider": "Google",
      "family": "Gemma",
      "params": 9,
      "context": 8192,
      "ram": 18,
      "vram": 8,
      "quants": ["Q4_K_M", "Q5_K_M", "Q8_0"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "Qwen2.5 7B",
      "provider": "Alibaba",
      "family": "Qwen",
      "params": 7,
      "context": 32768,
      "ram": 16,
      "vram": 6,
      "quants": ["Q4_K_M", "Q5_K_M", "Q8_0"],
      "use_case": "general",
      "tags": ["chat", "multilingual"],
      "is_moe": false
    },
    {
      "name": "Qwen2.5-Coder 7B",
      "provider": "Alibaba",
      "family": "Qwen",
      "params": 7,
      "context": 32768,
      "ram": 16,
      "vram": 6,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "coding",
      "tags": ["code"],
      "is_moe": false
    },
    {
      "name": "DeepSeek-R1 7B",
      "provider": "DeepSeek",
      "family": "DeepSeek",
      "params": 7,
      "context": 32768,
      "ram": 16,
      "vram": 6,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "reasoning",
      "tags": ["reasoning", "math"],
      "is_moe": false
    },
    {
      "name": "StarCoder2 7B",
      "provider": "BigCode",
      "family": "StarCoder",
      "params": 7,
      "context": 16384,
      "ram": 16,
      "vram": 6,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "coding",
      "tags": ["code"],
      "is_moe": false
    },
    {
      "name": "LLaMA 2 13B",
      "provider": "Meta",
      "family": "LLaMA",
      "params": 13,
      "context": 4096,
      "ram": 24,
      "vram": 10,
      "quants": ["Q3_K_M", "Q4_K_M", "Q5_K_M"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "CodeLlama 13B",
      "provider": "Meta",
      "family": "CodeLlama",
      "params": 13,
      "context": 16384,
      "ram": 24,
      "vram": 10,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "coding",
      "tags": ["code"],
      "is_moe": false
    },
    {
      "name": "Mistral Nemo 12B",
      "provider": "Mistral AI",
      "family": "Mistral",
      "params": 12,
      "context": 128000,
      "ram": 24,
      "vram": 10,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "Qwen2.5 14B",
      "provider": "Alibaba",
      "family": "Qwen",
      "params": 14,
      "context": 32768,
      "ram": 28,
      "vram": 12,
      "quants": ["Q3_K_M", "Q4_K_M", "Q5_K_M"],
      "use_case": "general",
      "tags": ["chat", "multilingual"],
      "is_moe": false
    },
    {
      "name": "Phi-3 Medium 14B",
      "provider": "Microsoft",
      "family": "Phi",
      "params": 14,
      "context": 128000,
      "ram": 28,
      "vram": 12,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "coding",
      "tags": ["code", "reasoning"],
      "is_moe": false
    },
    {
      "name": "Yi 34B",
      "provider": "01-AI",
      "family": "Yi",
      "params": 34,
      "context": 4096,
      "ram": 48,
      "vram": 20,
      "quants": ["Q3_K_M", "Q4_K_M"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "CodeLlama 34B",
      "provider": "Meta",
      "family": "CodeLlama",
      "params": 34,
      "context": 16384,
      "ram": 48,
      "vram": 20,
      "quants": ["Q3_K_M", "Q4_K_M"],
      "use_case": "coding",
      "tags": ["code"],
      "is_moe": false
    },
    {
      "name": "Qwen2.5 32B",
      "provider": "Alibaba",
      "family": "Qwen",
      "params": 32,
      "context": 32768,
      "ram": 48,
      "vram": 20,
      "quants": ["Q3_K_M", "Q4_K_M"],
      "use_case": "general",
      "tags": ["chat", "multilingual"],
      "is_moe": false
    },
    {
      "name": "Gemma 2 27B",
      "provider": "Google",
      "family": "Gemma",
      "params": 27,
      "context": 8192,
      "ram": 48,
      "vram": 20,
      "quants": ["Q3_K_M", "Q4_K_M"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "DeepSeek-R1 32B",
      "provider": "DeepSeek",
      "family": "DeepSeek",
      "params": 32,
      "context": 32768,
      "ram": 48,
      "vram": 20,
      "quants": ["Q3_K_M", "Q4_K_M"],
      "use_case": "reasoning",
      "tags": ["reasoning", "math"],
      "is_moe": false
    },
    {
      "name": "Mixtral 8x7B",
      "provider": "Mistral AI",
      "family": "Mixtral",
      "params": 47,
      "context": 32768,
      "ram": 48,
      "vram": 24,
      "quants": ["Q3_K_M", "Q4_K_M"],
      "use_case": "general",
      "tags": ["chat", "moe"],
      "is_moe": true
    },
    {
      "name": "Mixtral 8x22B",
      "provider": "Mistral AI",
      "family": "Mixtral",
      "params": 141,
      "context": 65536,
      "ram": 96,
      "vram": 48,
      "quants": ["Q2_K", "Q3_K_M"],
      "use_case": "general",
      "tags": ["chat", "moe"],
      "is_moe": true
    },
    {
      "name": "LLaMA 3 70B",
      "provider": "Meta",
      "family": "LLaMA",
      "params": 70,
      "context": 8192,
      "ram": 64,
      "vram": 48,
      "quants": ["Q2_K", "Q3_K_M", "Q4_K_M"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "LLaMA 3.1 70B",
      "provider": "Meta",
      "family": "LLaMA",
      "params": 70,
      "context": 128000,
      "ram": 64,
      "vram": 48,
      "quants": ["Q2_K", "Q3_K_M", "Q4_K_M"],
      "use_case": "general",
      "tags": ["chat"],
      "is_moe": false
    },
    {
      "name": "Qwen2.5 72B",
      "provider": "Alibaba",
      "family": "Qwen",
      "params": 72,
      "context": 32768,
      "ram": 64,
      "vram": 48,
      "quants": ["Q2_K", "Q3_K_M", "Q4_K_M"],
      "use_case": "general",
      "tags": ["chat", "multilingual"],
      "is_moe": false
    },
    {
      "name": "DeepSeek-R1 70B",
      "provider": "DeepSeek",
      "family": "DeepSeek",
      "params": 70,
      "context": 32768,
      "ram": 64,
      "vram": 48,
      "quants": ["Q2_K", "Q3_K_M"],
      "use_case": "reasoning",
      "tags": ["reasoning", "math"],
      "is_moe": false
    },
    {
      "name": "LLaMA 3.2 Vision 11B",
      "provider": "Meta",
      "family": "LLaMA",
      "params": 11,
      "context": 128000,
      "ram": 20,
      "vram": 10,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "vision",
      "tags": ["vision", "multimodal"],
      "is_moe": false
    },
    {
      "name": "Qwen2-VL 7B",
      "provider": "Alibaba",
      "family": "Qwen",
      "params": 7,
      "context": 32768,
      "ram": 16,
      "vram": 8,
      "quants": ["Q4_K_M", "Q5_K_M"],
      "use_case": "vision",
      "tags": ["vision", "multimodal"],
      "is_moe": false
    },
    {
      "name": "nomic-embed-text",
      "provider": "Nomic",
      "family": "Nomic",
      "params": 0.137,
      "context": 8192,
      "ram": 2,
      "vram": 1,
      "quants": ["Q4_K_M", "Q8_0"],
      "use_case": "embedding",
      "tags": ["embedding"],
      "is_moe": false
    },
    {
      "name": "mxbai-embed-large",
      "provider": "MixedBread",
      "family": "BERT",
      "params": 0.335,
      "context": 512,
      "ram": 2,
      "vram": 1,
      "quants": ["Q4_K_M", "Q8_0"],
      "use_case": "embedding",
      "tags": ["embedding"],
      "is_moe": false
    }
  ]
}
